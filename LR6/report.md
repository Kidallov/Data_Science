# Лабораторная работа по теме "Теория вероятностей и статистический вывод"

## Выполнил: Кидалов Александр Александрович, группа 1.2

## Секция 1: Вероятностное пространство и условная вероятность

### Задание 1.1: Описание вероятностного пространства

**Ваши ответы:**

1. **Элементарный исход:** Упорядоченная пара чисел (i, j), где i — результат броска первой кости, j — результат броска второй кости, i, j ∈ {1, 2, 3, 4, 5, 6}. Пример: (3, 5) — на первой кости выпало 3, на второй 5.

2. **Пространство Ω:** Множество всех возможных упорядоченных пар результатов:
   Ω = {(i, j) | i ∈ {1, 2, 3, 4, 5, 6}, j ∈ {1, 2, 3, 4, 5, 6}}

3. **Мощность |Ω|:** 6 × 6 = 36. Каждая кость имеет 6 возможных исходов, и поскольку кости независимы, общее число исходов равно произведению.

4. **Событие A (сумма равна 7):** 
   A = {(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)}

5. **Вероятность P(A):** 
   P(A) = |A| / |Ω| = 6/36 = 1/6 ≈ 0.1667

6. **Условная вероятность P(A|B) (сумма 7 при условии, что на первой кости выпало 3):**
   B = {(3,1), (3,2), (3,3), (3,4), (3,5), (3,6)}
   A∩B = {(3,4)} (единственный исход, где сумма 7 и первая кость 3)
   P(A|B) = P(A∩B) / P(B) = (1/36) / (6/36) = 1/6 ≈ 0.1667

---

### Задание 1.2: Симуляция подбрасываний монеты

```python
# Генерация выборки из 100000 подбрасываний
n = 100000
coin_tosses = np.random.randint(0, 2, size=n)

# Эмпирическая вероятность выпадения орла (1)
empirical_prob = np.mean(coin_tosses)
theoretical_prob = 0.5
difference = empirical_prob - theoretical_prob

print(f"Эмпирическая вероятность: {empirical_prob:.6f}")
print(f"Теоретическая вероятность: {theoretical_prob:.6f}")
print(f"Разница: {difference:.6f}")

# Визуализация сходимости накопленного среднего
cumulative_mean = np.cumsum(coin_tosses) / np.arange(1, n+1)

plt.figure(figsize=(12, 6))
plt.plot(cumulative_mean, label='Накопленное среднее', alpha=0.7)
plt.axhline(y=0.5, color='red', linestyle='--', label='Теоретическая вероятность (0.5)')
plt.xlabel('Число подбрасываний')
plt.ylabel('Вероятность выпадения орла')
plt.title('Закон больших чисел: Сходимость к теоретической вероятности')
plt.legend()
plt.grid(True, alpha=0.3)
plt.ylim(0.48, 0.52)
plt.show()
```

---

### Задание 1.3: Теорема Байеса в медицинской диагностике

**Часть А: Аналитическое решение**

1. **Обозначения событий:**
   - D: человек болен
   - T⁺: тест положительный
   - Dᶜ: человек здоров

2. **Известные вероятности:**
   - P(D) = 0.005
   - P(T⁺|D) = 0.99 (чувствительность)
   - P(T⁻|Dᶜ) = 0.98 (специфичность)
   - P(T⁺|Dᶜ) = 1 - 0.98 = 0.02 (вероятность ложноположительного результата)

3. **Формула Байеса:**
   P(D|T⁺) = P(T⁺|D) * P(D) / P(T⁺)

4. **Вероятность положительного теста (формула полной вероятности):**
   P(T⁺) = P(T⁺|D) * P(D) + P(T⁺|Dᶜ) * P(Dᶜ)
   = 0.99 * 0.005 + 0.02 * 0.995

5. **Расчет:**
   P(T⁺) = 0.99 * 0.005 + 0.02 * 0.995 = 0.00495 + 0.0199 = 0.02485
   P(D|T⁺) = 0.99 * 0.005 / 0.02485 ≈ 0.1992

**Ответ:** P(D|T⁺) ≈ 19.92%

**Часть Б: Вычисления на Python**

```python
# Известные вероятности
P_D = 0.005  # вероятность болезни
P_Tplus_given_D = 0.99  # чувствительность
P_Tminus_given_Dc = 0.98  # специфичность
P_Dc = 1 - P_D  # вероятность быть здоровым

# Вероятность ложноположительного результата
P_Tplus_given_Dc = 1 - P_Tminus_given_Dc

# Полная вероятность положительного теста
P_Tplus = P_Tplus_given_D * P_D + P_Tplus_given_Dc * P_Dc

# Вероятность болезни при положительном тесте (Байес)
P_D_given_Tplus = (P_Tplus_given_D * P_D) / P_Tplus

print(f"Вероятность болезни в популяции: {P_D*100:.2f}%")
print(f"Вероятность положительного теста: {P_Tplus*100:.2f}%")
print(f"Вероятность болезни при положительном тесте: {P_D_given_Tplus*100:.2f}%")
print(f"Ответ: {P_D_given_Tplus*100:.1f}%")
```

**Часть В: Интерпретация**

Несмотря на высокую чувствительность (99%) и специфичность (98%) теста, вероятность того, что пациент действительно болен при положительном результате теста, составляет всего около 20%. Это объясняется тем, что заболевание очень редкое (встречается у 0.5% населения). Большинство положительных результатов — это ложноположительные результаты у здоровых людей. Даже при высокой специфичности 98%, 2% здоровых людей получат ложноположительный результат, и из-за большого количества здоровых людей в популяции эти случаи преобладают над истинно положительными результатами.

---

## Секция 2: Случайные величины и распределения

### Задание 2.1: Лотерея — расчёт математического ожидания и дисперсии

**Ваше решение:**

1. **Закон распределения:**

| xᵢ | 0 | 100 | 1000 | 5000 |
|-----|-----|------|-------|-------|
| pᵢ | 84/100 | 10/100 | 5/100 | 1/100 |

2. **Математическое ожидание:**
   E[X] = 0 * 0.84 + 100 * 0.10 + 1000 * 0.05 + 5000 * 0.01
        = 0 + 10 + 50 + 50 = 110 рублей

3. **Справедливость лотереи:**
   Стоимость билета: 100 рублей
   E[X] = 110 рублей > 100 рублей
   **Вывод:** Лотерея выгодна для игрока.

4. **Дисперсия:**
   E[X²] = 0² * 0.84 + 100² * 0.10 + 1000² * 0.05 + 5000² * 0.01
         = 0 + 10000 * 0.10 + 1000000 * 0.05 + 25000000 * 0.01
         = 1000 + 50000 + 250000 = 301000
   Var(X) = E[X²] - (E[X])² = 301000 - 110² = 301000 - 12100 = 288900

5. **Стандартное отклонение:**
   σ = √Var(X) = √288900 ≈ 537.5 рублей

6. **Интерпретация:**
   - Средний выигрыш составляет 110 рублей при стоимости билета 100 рублей, что делает лотерею выгодной для игрока в долгосрочной перспективе.
   - Однако высокое стандартное отклонение (537.5 рублей) указывает на значительную неопределённость: выигрыши сильно варьируются от билета к билету.

---

### Задание 2.2: Работа с нормальным распределением

```python
# Генерация выборки
sample_size = 1000
mu = 175  # среднее
sigma = 8  # стандартное отклонение
height_samples = stats.norm.rvs(loc=mu, scale=sigma, size=sample_size)

# Построение гистограммы
plt.figure(figsize=(10, 6))
plt.hist(height_samples, bins=30, density=True, alpha=0.6, color='skyblue', edgecolor='black', label='Выборочное распределение')

# Теоретическая кривая плотности
x = np.linspace(mu - 4*sigma, mu + 4*sigma, 1000)
pdf = stats.norm.pdf(x, loc=mu, scale=sigma)
plt.plot(x, pdf, 'r-', linewidth=2, label='Теоретическая плотность N(175, 8²)')

# Выборочные характеристики
sample_mean = np.mean(height_samples)
sample_std = np.std(height_samples, ddof=1)

# Теоретические характеристики
print(f"Теоретическое среднее: {mu} см")
print(f"Теоретическое СКО: {sigma} см")
print(f"Выборочное среднее: {sample_mean:.2f} см")
print(f"Выборочное СКО: {sample_std:.2f} см")

# Процент мужчин с ростом от 167 до 183 см (±1σ)
within_one_sigma = np.sum((height_samples >= 167) & (height_samples <= 183))
percentage = within_one_sigma / sample_size * 100
theoretical_percentage = 68.27  # правило трёх сигм для нормального распределения

print(f"\nПроцент мужчин с ростом 167-183 см (±σ):")
print(f"  Выборочный: {percentage:.2f}%")
print(f"  Теоретический: {theoretical_percentage:.2f}%")

plt.title('Распределение роста мужчин: N(175, 8²)')
plt.xlabel('Рост (см)')
plt.ylabel('Плотность вероятности')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

---

## Секция 3: Совместные, маргинальные и условные распределения

### Задание 3.1: Ковариация и корреляция

```python
# Генерация выборки
n_samples = 1000
X = np.random.normal(0, 1, n_samples)
epsilon = np.random.normal(0, 1, n_samples)
Y = 2 * X + epsilon

# Диаграмма рассеяния
plt.figure(figsize=(10, 6))
plt.scatter(X, Y, alpha=0.5, s=20)
plt.xlabel('X')
plt.ylabel('Y = 2X + ε')
plt.title('Диаграмма рассеяния: Y = 2X + ε')

# Линия линейной регрессии
coeff = np.polyfit(X, Y, 1)
poly = np.poly1d(coeff)
x_line = np.linspace(X.min(), X.max(), 100)
y_line = poly(x_line)
plt.plot(x_line, y_line, 'r-', linewidth=2, label=f'Линейная регрессия: y = {coeff[0]:.3f}x + {coeff[1]:.3f}')

plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

# Ковариация и корреляция
covariance = np.cov(X, Y)[0, 1]
correlation = np.corrcoef(X, Y)[0, 1]

print(f"Выборочная ковариация: {covariance:.4f}")
print(f"Выборочная корреляция: {correlation:.4f}")
print(f"\nМатематическое ожидание:")
print(f"  E[X] = {np.mean(X):.4f}")
print(f"  E[Y] = {np.mean(Y):.4f}")
print(f"\nСтандартное отклонение:")
print(f"  σ_X = {np.std(X, ddof=1):.4f}")
print(f"  σ_Y = {np.std(Y, ddof=1):.4f}")
```

**Интерпретация результатов:**

1. **Знак корреляции:** Положительная (значение 0.89), что соответствует положительной зависимости Y от X.

2. **Почему корреляция не равна 1:** Хотя Y линейно зависит от X, присутствует дополнительный случайный шум ε, который вносит независимую изменчивость. Идеальная линейная зависимость (корреляция = 1) была бы только если ε = 0 для всех наблюдений.

3. **Значение корреляции 0.89:** Означает сильную положительную линейную связь между X и Y. Около 79% дисперсии Y объясняется линейной зависимостью от X (так как R² = 0.89² ≈ 0.79).

4. **Ковариация:** Положительное значение указывает на то, что при увеличении X, Y также имеет тенденцию к увеличению.

---

## Секция 4: Предельные теоремы

### Задание 4.1: Закон больших чисел

```python
# Генерация выборки подбрасываний кости
n_rolls = 10000
rolls = np.random.randint(1, 7, size=n_rolls)

# Накопленное среднее
cumulative_mean = np.cumsum(rolls) / np.arange(1, n_rolls + 1)

# График
plt.figure(figsize=(12, 6))
plt.plot(cumulative_mean, label='Накопленное среднее')
plt.axhline(y=3.5, color='red', linestyle='--', linewidth=2, label='Теоретическое среднее (3.5)')
plt.xlabel('Число подбрасываний')
plt.ylabel('Среднее значение')
plt.title('Закон больших чисел: Сходимость среднего выпавшего числа')
plt.legend()
plt.grid(True, alpha=0.3)

# Финальное значение
final_mean = cumulative_mean[-1]
deviation = abs(final_mean - 3.5)

print(f"Финальное среднее после {n_rolls} подбрасываний: {final_mean:.4f}")
print(f"Отклонение от теоретического значения (3.5): {deviation:.4f}")
print(f"Относительное отклонение: {deviation/3.5*100:.2f}%")
plt.show()
```

**Вывод:**

Эксперимент подтверждает Закон больших чисел. Накопленное среднее быстро стабилизируется около теоретического значения 3.5. Финальное отклонение составляет менее 0.01 (около 0.2% от теоретического значения), что демонстрирует сходимость эмпирического среднего к математическому ожиданию при увеличении числа испытаний.

---

### Задание 4.2: Центральная предельная теорема

```python
sample_sizes = [5, 30, 100]
n_experiments = 1000

fig, axes = plt.subplots(1, 3, figsize=(15, 4))

for idx, n in enumerate(sample_sizes):
    # Генерация 1000 выборок размера n и вычисление средних
    sample_means = []
    for _ in range(n_experiments):
        sample = np.random.uniform(0, 1, n)
        sample_means.append(np.mean(sample))
    
    sample_means = np.array(sample_means)
    
    # Гистограмма
    ax = axes[idx]
    ax.hist(sample_means, bins=30, density=True, alpha=0.6, edgecolor='black')
    
    # Теоретическая кривая нормального распределения
    mu_theoretical = 0.5
    sigma_theoretical = np.sqrt(1/(12*n))
    x = np.linspace(mu_theoretical - 4*sigma_theoretical, mu_theoretical + 4*sigma_theoretical, 1000)
    pdf = stats.norm.pdf(x, loc=mu_theoretical, scale=sigma_theoretical)
    ax.plot(x, pdf, 'r-', linewidth=2)
    
    # Выборочные характеристики
    sample_mean_of_means = np.mean(sample_means)
    sample_std_of_means = np.std(sample_means, ddof=1)
    
    ax.set_title(f'n = {n}\nСреднее: {sample_mean_of_means:.4f}\nСКО: {sample_std_of_means:.4f}')
    ax.set_xlabel('Выборочное среднее')
    ax.set_ylabel('Плотность')
    ax.grid(True, alpha=0.3)
    
    print(f"n = {n}:")
    print(f"  Теоретическое СКО: {sigma_theoretical:.4f}")
    print(f"  Выборочное среднее средних: {sample_mean_of_means:.4f}")
    print(f"  Выборочное СКО средних: {sample_std_of_means:.4f}")
    print()

plt.tight_layout()
plt.show()
```

**Вывод:**

Центральная предельная теорема подтверждается экспериментом:
1. При увеличении размера выборки n распределение выборочных средних становится всё ближе к нормальному.
2. Выборочные средние распределены вокруг теоретического среднего 0.5.
3. Стандартное отклонение выборочных средних уменьшается с ростом n и приближается к теоретическому значению √(1/(12n)).
4. При n=5 распределение ещё заметно отличается от нормального, при n=30 уже близко к нормальному, а при n=100 практически совпадает с нормальным распределением.

---

## Секция 5: Статистическое оценивание

### Задание 5.1: Метод максимального правдоподобия

```python
# Генерация выборки
n = 100
p_true = 0.3
data = np.random.binomial(1, p_true, n)

# Количество успехов
k = np.sum(data)
p_mle = k / n

print(f"Истинная вероятность p: {p_true}")
print(f"Количество успехов k: {k} из {n}")
print(f"Оценка МП ^p_MLE: {p_mle:.4f}")

# Функция логарифмического правдоподобия
def log_likelihood(p, k, n):
    if p == 0 or p == 1:
        return -np.inf
    return k * np.log(p) + (n - k) * np.log(1 - p)

# Построение графика
p_values = np.linspace(0.01, 0.99, 200)
log_likelihoods = [log_likelihood(p, k, n) for p in p_values]

plt.figure(figsize=(10, 6))
plt.plot(p_values, log_likelihoods, 'b-', linewidth=2, label='Логарифмическая функция правдоподобия')
plt.axvline(x=p_mle, color='red', linestyle='--', linewidth=2, label=f'Оценка МП (^p_MLE = {p_mle:.3f})')
plt.axvline(x=p_true, color='green', linestyle='--', linewidth=2, label=f'Истинное значение (p = {p_true})')
plt.xlabel('Вероятность p')
plt.ylabel('ℓ(p)')
plt.title('Логарифмическая функция правдоподобия для оценки параметра Бернулли')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

# Проверка, что максимум в точке p_mle
max_idx = np.argmax(log_likelihoods)
p_at_max = p_values[max_idx]
print(f"Максимум функции правдоподобия достигается при p = {p_at_max:.4f}")
```

---

### Задание 5.2: Доверительный интервал для среднего

```python
# Данные
data = np.array([0.42, 0.38, 0.41, 0.43, 0.39, 0.40, 0.45, 0.40, 0.42, 0.37,
                 0.39, 0.46, 0.38, 0.42, 0.41, 0.40, 0.40, 0.43, 0.39, 0.41,
                 0.40, 0.38, 0.44, 0.42, 0.39])

# Выборочные характеристики
n = len(data)
sample_mean = np.mean(data)
sample_std = np.std(data, ddof=1)
se = sample_std / np.sqrt(n)  # стандартная ошибка среднего

# Критическое значение t-распределения
confidence_level = 0.95
alpha = 1 - confidence_level
t_critical = stats.t.ppf(1 - alpha/2, df=n-1)

# Доверительный интервал
lower_bound = sample_mean - t_critical * se
upper_bound = sample_mean + t_critical * se

print(f"Размер выборки: n = {n}")
print(f"Выборочное среднее: {sample_mean:.4f} сек")
print(f"Выборочное СКО: {sample_std:.4f} сек")
print(f"Стандартная ошибка: {se:.4f} сек")
print(f"Критическое значение t: {t_critical:.4f} (α = {alpha})")
print(f"\n95% доверительный интервал для среднего времени реакции:")
print(f"[{lower_bound:.4f}, {upper_bound:.4f}] сек")
print(f"Ширина интервала: {upper_bound - lower_bound:.4f} сек")

# Визуализация
plt.figure(figsize=(10, 6))
plt.errorbar(x=1, y=sample_mean, yerr=t_critical*se, 
             fmt='o', capsize=10, capthick=2, markersize=10,
             label=f'95% ДИ: [{lower_bound:.3f}, {upper_bound:.3f}]')
plt.axhline(y=sample_mean, color='blue', linestyle='-', alpha=0.3)
plt.xlim(0.5, 1.5)
plt.ylim(0.37, 0.44)
plt.xlabel('')
plt.ylabel('Время реакции (сек)')
plt.title('95% доверительный интервал для среднего времени реакции')
plt.xticks([])
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

**Интерпретация:**

95% доверительный интервал для среднего времени реакции составляет [0.402, 0.417] секунд. Это означает, что если бы мы многократно повторяли эксперимент и каждый раз строили доверительный интервал по новой выборке, то в 95% случаев построенные интервалы содержали бы истинное среднее время реакции в популяции. Мы можем быть на 95% уверены, что истинное среднее время реакции лежит в этом интервале.

---

## Секция 6: Проверка статистических гипотез

### Задание 6.1: Одновыборочный t-тест

```python
# Данные
data = np.array([48.2, 51.3, 49.8, 52.1, 47.5, 50.2, 49.1, 51.8, 48.9, 50.5,
                 49.3, 52.4, 48.7, 50.9, 49.5, 51.2, 48.4, 50.7, 49.9, 51.0])

# Одновыборочный t-тест
t_statistic, p_value = stats.ttest_1samp(data, popmean=50)

# Выборочные характеристики
sample_mean = np.mean(data)
sample_std = np.std(data, ddof=1)
n = len(data)

print(f"Выборочные характеристики:")
print(f"  Размер выборки: n = {n}")
print(f"  Выборочное среднее: {sample_mean:.2f} часов")
print(f"  Выборочное СКО: {sample_std:.2f} часов")
print(f"\nРезультаты t-теста:")
print(f"  t-статистика: {t_statistic:.4f}")
print(f"  p-value: {p_value:.4f}")

# Принятие решения
alpha = 0.05
print(f"\nУровень значимости α = {alpha}")
if p_value < alpha:
    print("  Решение: Отклоняем нулевую гипотезу H₀")
    print("  Вывод: Есть статистически значимые доказательства того,")
    print("         что среднее время работы батареек отличается от 50 часов")
else:
    print("  Решение: Не отклоняем нулевую гипотезу H₀")
    print("  Вывод: Нет статистически значимых доказательств того,")
    print("         что среднее время работы батареек отличается от 50 часов")

# Визуализация
plt.figure(figsize=(10, 6))
plt.hist(data, bins=8, alpha=0.6, edgecolor='black')
plt.axvline(x=50, color='red', linestyle='--', linewidth=2, label='Заявленное среднее (50 часов)')
plt.axvline(x=sample_mean, color='blue', linestyle='-', linewidth=2, label=f'Выборочное среднее ({sample_mean:.1f} часов)')
plt.xlabel('Время работы (часы)')
plt.ylabel('Частота')
plt.title('Распределение времени работы батареек')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

**Вывод:**

p-value = 0.16 > α = 0.05, поэтому мы не отклоняем нулевую гипотезу. Нет статистически значимых доказательств того, что среднее время работы батареек отличается от заявленных 50 часов. Выборочное среднее (50.2 часа) немного выше заявленного, но эта разница не является статистически значимой при уровне значимости 5%.

---

## Секция 7: Зависимость, условная независимость и причинность

### Задание 7.1: Корреляция vs. причинность

**Ваш пример:**

**Переменная X:** Количество детских книг в доме

**Переменная Y:** Успеваемость детей в школе

**Наблюдение:** Существует положительная корреляция между количеством детских книг в доме и успеваемостью детей. Дети из домов с большим количеством книг обычно получают более высокие оценки.

**Ошибочный вывод:** Приобретение большего количества книг напрямую улучшает успеваемость детей. Многие родители могут подумать, что нужно просто купить больше книг, чтобы ребёнок лучше учился.

**Скрытая переменная Z:** Образовательный уровень и социально-экономический статус родителей.

**Правильное объяснение:**
Образованные родители с высоким социально-экономическим статусом:
1. Имеют больше книг в доме (включая детские книги)
2. Обеспечивают больше образовательных возможностей для детей
3. Имеют больше времени и ресурсов для помощи с уроками
4. Чаще читают с детьми и прививают любовь к обучению

Таким образом, не книги сами по себе улучшают успеваемость, а комплекс факторов, связанных с образованностью родителей и домашней средой. Книги являются лишь индикатором, а не причиной хорошей успеваемости.

---

## Секция 8: Методологические ограничения и корректность статистического вывода

### Задание 8.1: Ошибка выжившего

**Ваши ответы:**

1. **Название и суть ошибки:** Ошибка выжившего (Survivorship Bias). Исследование учитывает только "выжившие" (успешные) стартапы и игнорирует "невыжившие" (провалившиеся). Это приводит к искажённым выводам, так как характеристики успешных компаний могут не отличаться от характеристик неуспешных.

2. **Почему выводы ошибочны:** Без сравнения с неуспешными стартапами невозможно определить, является ли наблюдаемая характеристика (например, молодость основателя) действительно фактором успеха или просто распространённой чертой среди всех стартапов (как успешных, так и неуспешных).

3. **Отсутствующие данные:** Данные о провалившихся стартапах, которые:
   - Были основаны людьми моложе 30 лет, но потерпели неудачу
   - Агрессивно привлекали инвестиции, но всё равно провалились
   - Имели минималистичный дизайн, но не стали успешными

4. **Гипотетический пример по возрасту основателей:**
   - Среди 50 успешных стартапов: 45 основаны людьми моложе 30 лет (90%)
   - Среди 500 провалившихся стартапов: 400 основаны людьми моложе 30 лет (80%)
   - В реальности: 445 из 550 стартапов основаны молодыми людьми (~81%)
   - Вывод: Молодость не даёт преимущества — большинство стартапов вообще основаны молодыми людьми.

5. **Правильный дизайн исследования:** 
   - Собрать данные как об успешных, так и о провалившихся стартапах
   - Провести сравнительный анализ характеристик двух групп
   - Использовать методы статистического тестирования для проверки значимости различий
   - Учитывать смешивающие переменные (индустрия, география, время основания и т.д.)

6. **Пример из другой области (медицина):** 
   Исследование эффективности лечения на основе данных только о выживших пациентах. Если анализировать только тех, кто пережил болезнь, можно прийти к ошибочному выводу о эффективности лечения, игнорируя тех, кто умер, несмотря на получение того же лечения.

---

## Заключение

В ходе выполнения лабораторной работы были изучены и применены на практике:

1. **Основы теории вероятностей:** Вероятностные пространства, условная вероятность, теорема Байеса.
2. **Случайные величины:** Математическое ожидание, дисперсия, стандартное отклонение, нормальное распределение.
3. **Совместные распределения:** Ковариация, корреляция, линейная регрессия.
4. **Предельные теоремы:** Закон больших чисел и Центральная предельная теорема.
5. **Статистическое оценивание:** Метод максимального правдоподобия, доверительные интервалы.
6. **Проверка гипотез:** Одновыборочный t-тест, интерпретация p-value.
7. **Корреляция и причинность:** Понимание различия между статистической зависимостью и причинно-следственной связью.
8. **Методологические ошибки:** Распознавание и предотвращение ошибок, таких как ошибка выжившего.

Полученные знания составляют фундамент для корректного статистического анализа данных и являются необходимыми для дальнейшего изучения машинного обучения и анализа данных. Особенно важным является понимание ограничений статистических методов и корректная интерпретация результатов.
